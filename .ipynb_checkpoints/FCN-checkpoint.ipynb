{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoscrolling long output is disabled\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 24})\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "disable_js = \"\"\"\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def disable_scroll():\n",
    "    display(Javascript(disable_js))\n",
    "    print (\"autoscrolling long output is disabled\")\n",
    "    \n",
    "disable_scroll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/media/marsdenlab/Data2/brats/brats.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'X_negative', <HDF5 dataset \"X_negative\": shape (17986, 200, 200), type \"<f4\">), (u'X_positive', <HDF5 dataset \"X_positive\": shape (16114, 200, 200), type \"<f4\">), (u'Y_negative', <HDF5 dataset \"Y_negative\": shape (17986, 200, 200), type \"<f4\">), (u'Y_positive', <HDF5 dataset \"Y_positive\": shape (16114, 200, 200), type \"<f4\">)]\n",
      "X_p_train shape = (16114, 200, 200)\n",
      " Y_p_train shape = (16114, 200, 200)\n",
      " X_n_train shape = (17986, 200, 200)\n",
      " Y_n_train shape = (17986, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "data = h5py.File(data_path,'r')\n",
    "print data.items()\n",
    "X_p_train = data['X_positive']\n",
    "Y_p_train = data['Y_positive']\n",
    "X_n_train = data['X_negative']\n",
    "Y_n_train = data['Y_negative']\n",
    "\n",
    "print (\"X_p_train shape = {}\\n Y_p_train shape = {}\\n X_n_train shape = {}\\n Y_n_train shape = {}\".\n",
    "format(X_p_train.shape, Y_p_train.shape, X_n_train.shape, Y_n_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return tf.maximum(0.2*x,x)\n",
    "\n",
    "def conv2D(x, dims=[3, 3], filters=32, strides=[1, 1],\n",
    "           std=1e-3, padding='SAME', activation=tf.identity, scope='conv2d'):\n",
    "  \"\"\"\n",
    "  args:\n",
    "      x, (tf tensor), tensor with shape (batch,width,height,channels)\n",
    "      dims, (list), size of convolution filters\n",
    "      filters, (int), number of filters used\n",
    "      strides, (list), number of steps convolutions slide\n",
    "      std, (float/string), std of weight initialization, 'xavier' for xavier\n",
    "          initialization\n",
    "      padding, (string), 'SAME' or 'VALID' determines if input should be padded\n",
    "          to keep output dimensions the same or not\n",
    "      activation, (tf function), tensorflow activation function, e.g. tf.nn.relu\n",
    "      scope, (string), scope under which to store variables\n",
    "  returns:\n",
    "      a, (tf tensor), the output of the convolution layer, has size\n",
    "          (batch, new_width , new_height , filters)\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope):\n",
    "    s = x.get_shape().as_list()\n",
    "\n",
    "    shape = dims + [s[3], filters]\n",
    "\n",
    "    if std == 'xavier':\n",
    "      std = np.sqrt(2.0 / (s[1] * s[2] * s[3]))\n",
    "\n",
    "    W = tf.Variable(tf.random_normal(shape=shape, stddev=std), name='W')\n",
    "\n",
    "    b = tf.Variable(tf.ones([filters]) * std, name='b')\n",
    "\n",
    "    o = tf.nn.convolution(x, W, padding, strides=strides)\n",
    "\n",
    "    o = o + b\n",
    "\n",
    "    a = activation(o)\n",
    "\n",
    "    return a\n",
    "    \n",
    "def get_batch(Xp,Yp, Xn, Yn, n=32):\n",
    "    Np = Xp.shape[0]\n",
    "    Nn = Xn.shape[0]\n",
    "    \n",
    "    inds_p = sorted(np.random.choice(range(Np),size=n, replace=False))\n",
    "    inds_n = sorted(np.random.choice(range(Nn),size=n, replace=False))\n",
    "    \n",
    "    xp = Xp[inds_p,:,:]\n",
    "    yp = Yp[inds_p,:,:]\n",
    "    \n",
    "    xn = Xn[inds_n]\n",
    "    yn = Yn[inds_n]\n",
    "    \n",
    "    x = np.concatenate((xp,xn))\n",
    "    y = np.concatenate((yp,yn))\n",
    "    \n",
    "    x = x[:,:,:,np.newaxis]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 1000\n",
    "Nbatch = 16\n",
    "print_step = 100\n",
    "\n",
    "W = X_p_train.shape[1]\n",
    "H = W\n",
    "C = 1\n",
    "\n",
    "num_layers = 5\n",
    "filters = 16\n",
    "dims = [5,5]\n",
    "strides = [1,1]\n",
    "\n",
    "act = leaky_relu\n",
    "\n",
    "std=1e-2\n",
    "num_classes=4\n",
    "learning_rate=5e-3\n",
    "momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot:0\", shape=(?, 200, 200, 4), dtype=float32)\n",
      "Tensor(\"conv_final/Identity:0\", shape=(?, 200, 200, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow graph construction\n",
    "\n",
    "#construct input place holders\n",
    "x = tf.placeholder(shape=[None,W,H,C],dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None,W,H],dtype=tf.int32)\n",
    "\n",
    "y_truth = tf.one_hot(y,depth=num_classes,axis=3)\n",
    "print y_truth\n",
    "o = conv2D(x,dims=dims,filters=filters,strides=strides,std=std,\n",
    "           activation=act, scope='conv_1')\n",
    "\n",
    "for i in range(1,num_layers):\n",
    "    scope = 'conv_{}'.format(i)\n",
    "    o = conv2D(o,dims=dims,filters=filters,strides=strides,std=std,\n",
    "           activation=act, scope=scope)\n",
    "\n",
    "o = conv2D(o,dims=dims,filters=num_classes,strides=strides,std=std,\n",
    "           activation=tf.identity, scope='conv_final')\n",
    "print o\n",
    "yhat = tf.nn.softmax(o)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=o,labels=y_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct the optimizer and training operations\n",
    "opt = tf.train.MomentumOptimizer(learning_rate,momentum)\n",
    "train = opt.minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct the tensorflow session and initialize the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 Train: 1.37833726406\n",
      "iter: 100 Train: 0.0940686240792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8c13b1e85018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_p_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_p_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_n_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_n_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12ffa691bcb5>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(Xp, Yp, Xn, Yn, n)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028130695/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028130695/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/marsdenlab/anaconda2/lib/python2.7/site-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Start the train loop\n",
    "train_hist = []\n",
    "#val_hist = []\n",
    "\n",
    "for i in range(train_steps):\n",
    "    xb,yb = get_batch(X_p_train,Y_p_train,X_n_train,Y_n_train,n=Nbatch)\n",
    "    l,_=sess.run([loss,train],{x:xb,y:yb})\n",
    "\n",
    "    if i%print_step == 0:\n",
    "        #xb,yb = get_batch(X_val,Y_val,Nval,n=Nbatch)\n",
    "        #lval=sess.run(loss,{x:xb,y:yb})\n",
    "        print \"iter: {} Train: {}\".format(i,l)\n",
    "        train_hist.append(l)\n",
    "        #val_hist.append(lval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
